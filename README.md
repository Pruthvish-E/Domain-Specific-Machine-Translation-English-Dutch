# Domain-Specific Machine Translation â€” English â†’ Dutch (Software Domain)

This project implements and evaluates **domain-adaptation pipelines** for Englishâ†’Dutch machine translation, targeting **software and technical localization content**.

Two complementary paradigms are explored:

1. **Encoderâ€“decoder neural MT** (classical domain fine-tuning)
2. **Decoder-only large language model adaptation** (LoRA instruction tuning)

Both approaches are evaluated on:
- a **general-domain benchmark** (FLORES-200 devtest)
- a **software-domain dataset** (provided)

The goal is to demonstrate **end-to-end MT engineering competence**, including data ingestion, training pipelines, evaluation methodology, and analysis.

---

## ğŸ“‚ Repository Structure

challenge_1_mt/

â”‚

â”œâ”€â”€ data/

â”‚ â”œâ”€â”€ raw/

â”‚ â”‚ â”œâ”€â”€ flores200_dataset/

â”‚ â”‚ â””â”€â”€ Dataset_Challenge_1.xlsx

â”‚ â””â”€â”€ processed/

â”‚ â”œâ”€â”€ flores_en_nl/

â”‚ â”œâ”€â”€ software_mt/

â”‚ â””â”€â”€ software_instruct/

â”‚

â”œâ”€â”€ training/

â”‚ â”œâ”€â”€ encdec_train.py

â”‚ â”œâ”€â”€ build_instruction_dataset.py

â”‚ â””â”€â”€ deconly_lora_train.py

â”‚

â”œâ”€â”€ evaluation/

â”‚ â”œâ”€â”€ utils.py

â”‚ â”œâ”€â”€ run_encdec_baseline.py

| â”œâ”€â”€ run_encdec_finetuned.py

| â”œâ”€â”€ run_decoder_only_LoRA_finetuned.py

â”‚ â”œâ”€â”€ run_decoder_only_baseline.py

â”‚ â””â”€â”€ aggregate_and_visualize.py

â”‚

â”œâ”€â”€ results/

â”‚ â”œâ”€â”€ *_predictions.csv

â”‚ â”œâ”€â”€ *_metrics.csv

â”‚ â”œâ”€â”€ metrics_summary.csv

â”‚ â”œâ”€â”€ bleu_comparison.png

â”‚ â”œâ”€â”€ chrf_comparison.png

â”‚ â””â”€â”€ domain_shift.png

â”‚

â”œâ”€â”€ report.md

â””â”€â”€ README.md



---

## ğŸ¯ Objectives

- Design a **software-domain fine-tuning pipeline** for a small encoderâ€“decoder Transformer.
- Implement a **decoder-only LoRA instruction-tuning pipeline**.
- Evaluate both on:
  - general-domain text (FLORES-200)
  - software-domain text (provided dataset)
- Report quantitative and qualitative analysis.

---

## ğŸ“Š Datasets

### General domain
- FLORES-200 devtest (Englishâ€“Dutch)

### Software domain
- Provided Excel dataset (UI strings, technical/system messages)

### Training corpus
- OPUS-100 (enâ€“nl)

All datasets are normalized into Hugging Faceâ€™s standard `translation` schema.

---

## ğŸ¤– Models

### Encoderâ€“decoder
- `Helsinki-NLP/opus-mt-en-nl`
- MarianMT architecture

### Decoder-only
- `Qwen/Qwen2.5-3B-Instruct`
- QLoRA + instruction tuning

---

## âš™ï¸ Setup

### Environment

- pip install -U transformers datasets sacrebleu evaluate sentencepiece pandas openpyxl \
- peft bitsandbytes accelerate pytorch-lightning matplotlib


## ğŸ§± Data preparation
python data/prepare_software_dataset.py
python data/prepare_flores.py
python training/build_instruction_dataset.py

## ğŸ§ª Baseline evaluation

### Encoderâ€“decoder baseline:

python evaluation/run_encdec_baseline.py

### Decoder-only baseline:

python evaluation/run_decoder_only_baseline.py

## ğŸ—ï¸ Training pipelines

### Encoderâ€“decoder domain fine-tuning
python training/encdec_train.py

### Features:

- OPUS-100 training corpus

- domain prefix tokens

- BLEU-based validation

- mixed precision

### Decoder-only LoRA instruction tuning
python training/deconly_lora_train.py

### Features:

- instruction formatting

- 4-bit quantization

- LoRA adapters

- software-domain specialization

## ğŸ“ˆ Metrics aggregation & visualization

python evaluation/aggregate_and_visualize.py

### Generates:

- results/metrics_summary.csv

- BLEU comparison plot

- chrF++ comparison plot

- Domain-shift analysis plot

### ğŸ“„ Final report

report.md

### Includes:
- methodology

- results

- graphs

- analysis

- limitations

## ğŸ§  Key Engineering Highlights

- Dual MT paradigms (classical NMT + LLMs)

- Domain adaptation strategies

- Instruction tuning

- Low-VRAM LoRA setup

- General vs in-domain evaluation

- Automated metrics + visualizations

- Reproducible pipelines

## âš ï¸ Notes

- Fine-tuning is intentionally lightweight to fit time and compute constraints.

- The primary objective is pipeline correctness, evaluation design, and domain analysis.

- The provided dataset is used strictly for in-domain evaluation.

## âœ… Deliverables

- Full data processing pipeline

- Two fine-tuning architectures

- Evaluation harness

- Visualization and reporting layer

- Reproducible research-style project layout

# ğŸ‘¤ Author

## Pruthvish Eshwar


 



